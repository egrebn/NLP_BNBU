{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9d0afd",
   "metadata": {},
   "source": [
    "# Formulaic Sentence Detection in Tang Dynasty Edicts\n",
    "\n",
    "This notebook identifies **formulaic sentences** (standardized phrases that appear across multiple edicts) versus **unique sentences** (edict-specific content) in Tang Dynasty imperial edicts using SIKU-BERT embeddings and cosine similarity.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Imperial edicts often follow conventional templates with formulaic language interspersed with context-specific content. This analysis helps distinguish between:\n",
    "\n",
    "- **Formulaic sentences**: Phrases that appear repeatedly across different edicts with high semantic similarity (‚â• threshold)\n",
    "- **Unique sentences**: Edict-specific content with no close counterparts in other documents\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Segmentation**: Split each edict into sentences based on Chinese punctuation marks („ÄÇÔºõÔºÅÔºü)\n",
    "2. **Embedding**: Generate SIKU-BERT embeddings for all sentences\n",
    "3. **Similarity Analysis**: Compute cosine similarity between sentences across different edicts\n",
    "4. **Classification**: Mark sentences as formulaic if similarity ‚â• threshold (default 0.85)\n",
    "5. **Visualization**: Export formatted texts with bold highlighting for formulaic sentences\n",
    "6. **Interactive Exploration**: Compare edicts dynamically with selective highlighting\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Key parameters you can adjust:\n",
    "- `EDICT_TYPE`: The document type to analyze (e.g., 'ÂÜåÊñá', 'Âç≥‰ΩçËµ¶', 'ÊîπÂÖÉËµ¶')\n",
    "- `SIMILARITY_THRESHOLD`: Minimum cosine similarity to consider sentences formulaic (0.0-1.0)\n",
    "- `MIN_SENTENCE_LENGTH`: Minimum characters for a valid sentence\n",
    "\n",
    "## Outputs\n",
    "\n",
    "The notebook generates:\n",
    "1. **Markdown file**: Formatted texts with formulaic sentences in **bold**\n",
    "2. **CSV file**: Detailed sentence-level data with similarity scores\n",
    "3. **Interactive widget**: Dynamic edict comparison with highlighting\n",
    "\n",
    "Let's begin the analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4aa4f",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install all required Python packages for the analysis. This includes:\n",
    "- **pandas**: Data manipulation and CSV handling\n",
    "- **numpy**: Numerical computations\n",
    "- **torch**: PyTorch for running SIKU-BERT model\n",
    "- **transformers**: HuggingFace library for BERT models\n",
    "- **scikit-learn**: Cosine similarity computation\n",
    "- **tqdm**: Progress bars for long operations\n",
    "- **ipywidgets**: Interactive widgets for edict exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy torch transformers scikit-learn tqdm ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc46d8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe81b7",
   "metadata": {},
   "source": [
    "Import all necessary libraries and configure display settings. We suppress warnings to keep output clean and set pandas to display full column information for better visibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc9f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e683c",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196e15d",
   "metadata": {},
   "source": [
    "Set analysis parameters. **EDICT_TYPE** determines which document type to analyze. **SIMILARITY_THRESHOLD** controls how similar sentences must be to count as formulaic (0.85 = 85% similarity). Lower thresholds will identify more sentences as formulaic; higher thresholds will be more conservative. The notebook will automatically detect GPU availability for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EDICT_TYPE = 'ÂÜåÊñá'  # Change to analyze different edict types\n",
    "SIMILARITY_THRESHOLD = 0.85  # Sentences with similarity ‚â• this are considered formulaic\n",
    "MIN_SENTENCE_LENGTH = 5  # Minimum characters for a valid sentence\n",
    "MODEL_PATH = './sikubert'  # Path to local SIKU-BERT model\n",
    "OUTPUT_FILE = f'formulaic_analysis_{EDICT_TYPE}.md'  # Output Markdown file\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Edict type: {EDICT_TYPE}\")\n",
    "print(f\"  Similarity threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  Min sentence length: {MIN_SENTENCE_LENGTH}\")\n",
    "print(f\"  Model path: {MODEL_PATH}\")\n",
    "print(f\"  Output file: {OUTPUT_FILE}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617303ba",
   "metadata": {},
   "source": [
    "## 3. Load SIKU-BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f71c44",
   "metadata": {},
   "source": [
    "Load the SIKU-BERT model from the local path. SIKU-BERT is a BERT model specifically trained on classical Chinese texts from the Siku Quanshu (ÂõõÂ∫´ÂÖ®Êõ∏), making it ideal for analyzing Tang Dynasty documents. The model is set to evaluation mode (no training) and moved to GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13543919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading SIKU-BERT model from {MODEL_PATH}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModel.from_pretrained(MODEL_PATH)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce2487",
   "metadata": {},
   "source": [
    "## 4. Define Embedding Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf17ec2",
   "metadata": {},
   "source": [
    "Define the embedding generation function. This function converts text strings into dense vector representations (embeddings) using SIKU-BERT. We use the [CLS] token embedding as the sentence representation, which captures the overall semantic meaning. Batch processing improves efficiency when encoding many sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, batch_size=16):\n",
    "    \"\"\"\n",
    "    Generate SIKU-BERT embeddings for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings\n",
    "        batch_size: Number of texts to process at once\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings (num_texts, embedding_dim)\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Get embeddings\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # Use [CLS] token embedding\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            all_embeddings.append(embeddings)\n",
    "    \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "print(\"‚úÖ Embedding function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c8cac",
   "metadata": {},
   "source": [
    "## 5. Load and Segment Edicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ef2d8",
   "metadata": {},
   "source": [
    "Load the edict dataset from CSV and filter by document type. The CSV file contains extracted Tang Dynasty edicts with punctuated text. We select only edicts matching the specified type (e.g., 'ÂÜåÊñá') and ensure they have valid text content. The notebook displays all available edicts for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading edicts from extracted_edicts_punc.csv...\")\n",
    "\n",
    "df_all = pd.read_csv('extracted_edicts_punc.csv', encoding='utf-8-sig')\n",
    "\n",
    "# Filter by edict type\n",
    "df_edicts = df_all[\n",
    "    (df_all['document_type'] == EDICT_TYPE) & \n",
    "    (df_all['text_contents_punctuated'].notna())\n",
    "].copy()\n",
    "\n",
    "df_edicts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"\\nFound {len(df_edicts)} edicts of type '{EDICT_TYPE}'\")\n",
    "\n",
    "if len(df_edicts) < 2:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Need at least 2 edicts for comparison!\")\n",
    "    print(\"   Please choose a different EDICT_TYPE with more examples.\")\n",
    "else:\n",
    "    print(\"\\nEdicts:\")\n",
    "    for idx, row in df_edicts.iterrows():\n",
    "        print(f\"  {idx+1}. {row['text_title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73696b",
   "metadata": {},
   "source": [
    "Segment each edict into individual sentences. Chinese sentences are identified by major punctuation marks: „ÄÇ(period), Ôºõ(semicolon), ÔºÅ(exclamation), and Ôºü(question mark). We also track the position of each sentence within the original text for later reconstruction with formatting. Short fragments below MIN_SENTENCE_LENGTH are filtered out to avoid noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSegmenting edicts into sentences...\")\n",
    "\n",
    "def segment_sentences(text):\n",
    "    \"\"\"\n",
    "    Segment text into sentences based on Chinese punctuation.\n",
    "    \n",
    "    Returns:\n",
    "        List of (sentence_text, start_pos, end_pos) tuples\n",
    "    \"\"\"\n",
    "    # Split by major delimiters\n",
    "    parts = re.split(r'([„ÄÇÔºõÔºÅÔºü])', text)\n",
    "    \n",
    "    # Reconstruct sentences with delimiters\n",
    "    sentences = []\n",
    "    current_pos = 0\n",
    "    \n",
    "    for i in range(0, len(parts)-1, 2):\n",
    "        if i+1 < len(parts):\n",
    "            sent = parts[i] + parts[i+1]\n",
    "            sent = sent.strip()\n",
    "            \n",
    "            if len(sent) >= MIN_SENTENCE_LENGTH:\n",
    "                # Find position in original text\n",
    "                start_pos = text.find(sent, current_pos)\n",
    "                if start_pos == -1:\n",
    "                    start_pos = current_pos\n",
    "                end_pos = start_pos + len(sent)\n",
    "                \n",
    "                sentences.append((sent, start_pos, end_pos))\n",
    "                current_pos = end_pos\n",
    "    \n",
    "    # Handle last sentence without delimiter\n",
    "    if len(parts) % 2 == 1:\n",
    "        last_sent = parts[-1].strip()\n",
    "        if len(last_sent) >= MIN_SENTENCE_LENGTH:\n",
    "            start_pos = text.find(last_sent, current_pos)\n",
    "            if start_pos == -1:\n",
    "                start_pos = current_pos\n",
    "            end_pos = start_pos + len(last_sent)\n",
    "            sentences.append((last_sent, start_pos, end_pos))\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Segment all edicts\n",
    "edict_sentences = []  # List of dicts with metadata\n",
    "\n",
    "for idx, row in df_edicts.iterrows():\n",
    "    edict_title = row['text_title']\n",
    "    full_text = row['text_contents_punctuated']\n",
    "    \n",
    "    sentences = segment_sentences(full_text)\n",
    "    \n",
    "    for sent_idx, (sent_text, start_pos, end_pos) in enumerate(sentences):\n",
    "        edict_sentences.append({\n",
    "            'edict_idx': idx,\n",
    "            'edict_title': edict_title,\n",
    "            'sentence_idx': sent_idx,\n",
    "            'sentence_text': sent_text,\n",
    "            'start_pos': start_pos,\n",
    "            'end_pos': end_pos,\n",
    "            'full_text': full_text\n",
    "        })\n",
    "\n",
    "df_sentences = pd.DataFrame(edict_sentences)\n",
    "\n",
    "print(f\"‚úÖ Segmentation complete!\")\n",
    "print(f\"   Total sentences: {len(df_sentences)}\")\n",
    "print(f\"   Sentences per edict:\")\n",
    "for idx, row in df_edicts.iterrows():\n",
    "    count = len(df_sentences[df_sentences['edict_idx'] == idx])\n",
    "    print(f\"     {row['text_title']}: {count} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d8065",
   "metadata": {},
   "source": [
    "## 6. Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf3900",
   "metadata": {},
   "source": [
    "Generate SIKU-BERT embeddings for all sentences in the dataset. This converts each sentence from text into a numerical vector that captures its semantic meaning. The embedding process may take several minutes depending on the number of sentences and whether GPU acceleration is available. Progress is shown with a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6253da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating SIKU-BERT embeddings for {len(df_sentences)} sentences...\\n\")\n",
    "\n",
    "# Get all sentence texts\n",
    "sentence_texts = df_sentences['sentence_text'].tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = get_embeddings(sentence_texts, batch_size=16)\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings generated!\")\n",
    "print(f\"   Shape: {embeddings.shape}\")\n",
    "print(f\"   Memory: {embeddings.nbytes / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca95ea9",
   "metadata": {},
   "source": [
    "## 7. Compute Similarity and Identify Formulaic Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b2a1e",
   "metadata": {},
   "source": [
    "Compute pairwise cosine similarity between all sentences and identify formulaic patterns. For each sentence, we find its most similar counterpart from **other edicts** (not from the same edict). If the maximum similarity ‚â• threshold, the sentence is classified as formulaic. This approach ensures we're detecting cross-document patterns rather than internal repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb94e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Computing sentence similarities...\\n\")\n",
    "\n",
    "# Compute full similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(f\"‚úÖ Similarity matrix computed: {similarity_matrix.shape}\\n\")\n",
    "\n",
    "# For each sentence, find max similarity with sentences from OTHER edicts\n",
    "formulaic_flags = []\n",
    "max_similarities = []\n",
    "best_matches = []\n",
    "\n",
    "for i in tqdm(range(len(df_sentences)), desc=\"Identifying formulaic sentences\"):\n",
    "    current_edict_idx = df_sentences.iloc[i]['edict_idx']\n",
    "    \n",
    "    # Find indices of sentences from other edicts\n",
    "    other_edict_mask = df_sentences['edict_idx'] != current_edict_idx\n",
    "    other_edict_indices = df_sentences[other_edict_mask].index.tolist()\n",
    "    \n",
    "    if len(other_edict_indices) == 0:\n",
    "        # Only one edict - cannot compare\n",
    "        formulaic_flags.append(False)\n",
    "        max_similarities.append(0.0)\n",
    "        best_matches.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Get similarities to other edicts\n",
    "    similarities_to_others = similarity_matrix[i, other_edict_indices]\n",
    "    \n",
    "    # Find maximum similarity\n",
    "    max_sim = similarities_to_others.max()\n",
    "    max_sim_idx_in_others = similarities_to_others.argmax()\n",
    "    best_match_idx = other_edict_indices[max_sim_idx_in_others]\n",
    "    \n",
    "    # Determine if formulaic\n",
    "    is_formulaic = max_sim >= SIMILARITY_THRESHOLD\n",
    "    \n",
    "    formulaic_flags.append(is_formulaic)\n",
    "    max_similarities.append(max_sim)\n",
    "    best_matches.append(best_match_idx)\n",
    "\n",
    "# Add to dataframe\n",
    "df_sentences['is_formulaic'] = formulaic_flags\n",
    "df_sentences['max_similarity'] = max_similarities\n",
    "df_sentences['best_match_idx'] = best_matches\n",
    "\n",
    "# Statistics\n",
    "num_formulaic = df_sentences['is_formulaic'].sum()\n",
    "num_unique = len(df_sentences) - num_formulaic\n",
    "\n",
    "print(f\"\\n‚úÖ Formulaic identification complete!\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total sentences: {len(df_sentences)}\")\n",
    "print(f\"  Formulaic sentences (‚â•{SIMILARITY_THRESHOLD} similarity): {num_formulaic} ({num_formulaic/len(df_sentences)*100:.1f}%)\")\n",
    "print(f\"  Unique sentences: {num_unique} ({num_unique/len(df_sentences)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nFormulaic sentences by edict:\")\n",
    "for idx, row in df_edicts.iterrows():\n",
    "    edict_sents = df_sentences[df_sentences['edict_idx'] == idx]\n",
    "    num_form = edict_sents['is_formulaic'].sum()\n",
    "    total = len(edict_sents)\n",
    "    print(f\"  {row['text_title']}: {num_form}/{total} ({num_form/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eae439",
   "metadata": {},
   "source": [
    "## 8. Display Sample Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977467dd",
   "metadata": {},
   "source": [
    "Display representative examples of formulaic and unique sentences. Formulaic examples are sorted by similarity score to show the strongest patterns. For each formulaic sentence, we show both the original sentence and its best match from another edict. Unique examples demonstrate sentences with no close counterparts across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"SAMPLE FORMULAIC SENTENCES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "if num_formulaic > 0:\n",
    "    formulaic_sents = df_sentences[df_sentences['is_formulaic']].nlargest(5, 'max_similarity')\n",
    "    \n",
    "    for i, (idx, row) in enumerate(formulaic_sents.iterrows(), 1):\n",
    "        print(f\"\\n{'-' * 100}\")\n",
    "        print(f\"Example #{i}\")\n",
    "        print(f\"{'-' * 100}\")\n",
    "        print(f\"Edict: {row['edict_title']}\")\n",
    "        print(f\"Similarity: {row['max_similarity']:.3f}\")\n",
    "        print(f\"\\nSentence:\")\n",
    "        print(f\"  {row['sentence_text']}\")\n",
    "        \n",
    "        if row['best_match_idx'] is not None:\n",
    "            match_row = df_sentences.iloc[row['best_match_idx']]\n",
    "            print(f\"\\nBest match (from {match_row['edict_title']}):\")\n",
    "            print(f\"  {match_row['sentence_text']}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 100}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No formulaic sentences found with current threshold.\")\n",
    "    print(f\"   Consider lowering SIMILARITY_THRESHOLD (current: {SIMILARITY_THRESHOLD})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SAMPLE UNIQUE SENTENCES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "if num_unique > 0:\n",
    "    unique_sents = df_sentences[~df_sentences['is_formulaic']].nsmallest(5, 'max_similarity')\n",
    "    \n",
    "    for i, (idx, row) in enumerate(unique_sents.iterrows(), 1):\n",
    "        print(f\"\\n{'-' * 100}\")\n",
    "        print(f\"Example #{i}\")\n",
    "        print(f\"{'-' * 100}\")\n",
    "        print(f\"Edict: {row['edict_title']}\")\n",
    "        print(f\"Max similarity: {row['max_similarity']:.3f}\")\n",
    "        print(f\"\\nSentence:\")\n",
    "        print(f\"  {row['sentence_text']}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 100}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No unique sentences found - all sentences are formulaic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de30b3",
   "metadata": {},
   "source": [
    "## 9. Export to Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79e273",
   "metadata": {},
   "source": [
    "Export results to a formatted Markdown file for human reading. Each edict is reconstructed with **formulaic sentences in bold** and unique sentences in regular text. The file includes statistics for each edict and a summary at the top. This provides an easy way to read and analyze the complete texts with visual distinction between formulaic and unique content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Exporting results to {OUTPUT_FILE}...\\n\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    # Write header\n",
    "    f.write(f\"# Formulaic Sentence Analysis: {EDICT_TYPE}\\n\\n\")\n",
    "    f.write(f\"**Analysis Parameters:**\\n\")\n",
    "    f.write(f\"- Edict Type: {EDICT_TYPE}\\n\")\n",
    "    f.write(f\"- Number of Edicts: {len(df_edicts)}\\n\")\n",
    "    f.write(f\"- Similarity Threshold: {SIMILARITY_THRESHOLD}\\n\")\n",
    "    f.write(f\"- Total Sentences: {len(df_sentences)}\\n\")\n",
    "    f.write(f\"- Formulaic Sentences: {num_formulaic} ({num_formulaic/len(df_sentences)*100:.1f}%)\\n\")\n",
    "    f.write(f\"- Unique Sentences: {num_unique} ({num_unique/len(df_sentences)*100:.1f}%)\\n\")\n",
    "    f.write(f\"\\n**Legend:**\\n\")\n",
    "    f.write(f\"- **Bold text** = Formulaic sentence (similar to sentences in other edicts)\\n\")\n",
    "    f.write(f\"- Regular text = Unique sentence (no close counterparts in other edicts)\\n\")\n",
    "    f.write(f\"\\n---\\n\\n\")\n",
    "    \n",
    "    # Process each edict\n",
    "    for edict_idx, edict_row in df_edicts.iterrows():\n",
    "        edict_title = edict_row['text_title']\n",
    "        full_text = edict_row['text_contents_punctuated']\n",
    "        \n",
    "        # Get sentences for this edict\n",
    "        edict_sents = df_sentences[df_sentences['edict_idx'] == edict_idx].sort_values('sentence_idx')\n",
    "        \n",
    "        # Write edict header\n",
    "        f.write(f\"## {edict_title}\\n\\n\")\n",
    "        \n",
    "        # Statistics for this edict\n",
    "        num_form_edict = edict_sents['is_formulaic'].sum()\n",
    "        total_sents_edict = len(edict_sents)\n",
    "        f.write(f\"*Formulaic: {num_form_edict}/{total_sents_edict} sentences ({num_form_edict/total_sents_edict*100:.1f}%)*\\n\\n\")\n",
    "        \n",
    "        # Reconstruct text with formatting\n",
    "        # We'll process the full text and apply bold formatting\n",
    "        formatted_text = full_text\n",
    "        \n",
    "        # Sort sentences by position (reverse order for string replacement)\n",
    "        sorted_sents = edict_sents.sort_values('start_pos', ascending=False)\n",
    "        \n",
    "        for _, sent_row in sorted_sents.iterrows():\n",
    "            sent_text = sent_row['sentence_text']\n",
    "            start_pos = sent_row['start_pos']\n",
    "            end_pos = sent_row['end_pos']\n",
    "            is_formulaic = sent_row['is_formulaic']\n",
    "            \n",
    "            # Extract original sentence from full text\n",
    "            original_sent = full_text[start_pos:end_pos]\n",
    "            \n",
    "            # Apply formatting\n",
    "            if is_formulaic:\n",
    "                # Bold for formulaic\n",
    "                formatted_sent = f\"**{original_sent}**\"\n",
    "            else:\n",
    "                # Keep as-is for unique\n",
    "                formatted_sent = original_sent\n",
    "            \n",
    "            # Replace in formatted text\n",
    "            formatted_text = formatted_text[:start_pos] + formatted_sent + formatted_text[end_pos:]\n",
    "        \n",
    "        # Write formatted text\n",
    "        f.write(formatted_text)\n",
    "        f.write(\"\\n\\n---\\n\\n\")\n",
    "\n",
    "print(f\"‚úÖ Export complete!\")\n",
    "print(f\"\\nOutput file: {OUTPUT_FILE}\")\n",
    "print(f\"\\nThe file contains:\")\n",
    "print(f\"  - Complete text of all {len(df_edicts)} edicts\")\n",
    "print(f\"  - Formulaic sentences in **bold**\")\n",
    "print(f\"  - Unique sentences in regular text\")\n",
    "print(f\"  - Statistics for each edict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd2474",
   "metadata": {},
   "source": [
    "## 10. Create Detailed CSV Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409f654",
   "metadata": {},
   "source": [
    "Create a detailed CSV report with sentence-level analysis data. This machine-readable file contains every sentence with its classification (formulaic/unique), similarity score, and best matching sentence from other edicts. Useful for further statistical analysis, data processing, or integration with other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export detailed sentence-level data\n",
    "csv_file = f'formulaic_sentences_{EDICT_TYPE}.csv'\n",
    "\n",
    "# Prepare export data\n",
    "export_df = df_sentences[[\n",
    "    'edict_title', 'sentence_idx', 'sentence_text', \n",
    "    'is_formulaic', 'max_similarity'\n",
    "]].copy()\n",
    "\n",
    "# Add best match information\n",
    "best_match_titles = []\n",
    "best_match_texts = []\n",
    "\n",
    "for idx, row in df_sentences.iterrows():\n",
    "    if row['best_match_idx'] is not None and pd.notna(row['best_match_idx']):\n",
    "        match_row = df_sentences.iloc[int(row['best_match_idx'])]\n",
    "        best_match_titles.append(match_row['edict_title'])\n",
    "        best_match_texts.append(match_row['sentence_text'])\n",
    "    else:\n",
    "        best_match_titles.append('')\n",
    "        best_match_texts.append('')\n",
    "\n",
    "export_df['best_match_edict'] = best_match_titles\n",
    "export_df['best_match_sentence'] = best_match_texts\n",
    "\n",
    "export_df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ Detailed CSV report saved: {csv_file}\")\n",
    "print(f\"\\nCSV contains sentence-level data:\")\n",
    "print(f\"  - Edict title\")\n",
    "print(f\"  - Sentence index\")\n",
    "print(f\"  - Sentence text\")\n",
    "print(f\"  - Formulaic flag\")\n",
    "print(f\"  - Maximum similarity score\")\n",
    "print(f\"  - Best matching edict and sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb32e4",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238ef60",
   "metadata": {},
   "source": [
    "Display comprehensive summary statistics for the entire analysis. This includes overall formulaic/unique ratios, similarity score distributions, and per-edict breakdowns. The interpretation section helps contextualize the results by explaining what different levels of formulaic content might indicate about the document collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb01a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FORMULAIC SENTENCE ANALYSIS - SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Edict type: {EDICT_TYPE}\")\n",
    "print(f\"   Total edicts: {len(df_edicts)}\")\n",
    "print(f\"   Total sentences: {len(df_sentences)}\")\n",
    "\n",
    "print(f\"\\nüéØ Detection Results:\")\n",
    "print(f\"   Similarity threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"   Formulaic sentences: {num_formulaic} ({num_formulaic/len(df_sentences)*100:.1f}%)\")\n",
    "print(f\"   Unique sentences: {num_unique} ({num_unique/len(df_sentences)*100:.1f}%)\")\n",
    "\n",
    "if num_formulaic > 0:\n",
    "    formulaic_df = df_sentences[df_sentences['is_formulaic']]\n",
    "    print(f\"\\nüìà Similarity Metrics (Formulaic Sentences):\")\n",
    "    print(f\"   Mean similarity: {formulaic_df['max_similarity'].mean():.3f}\")\n",
    "    print(f\"   Median similarity: {formulaic_df['max_similarity'].median():.3f}\")\n",
    "    print(f\"   Min similarity: {formulaic_df['max_similarity'].min():.3f}\")\n",
    "    print(f\"   Max similarity: {formulaic_df['max_similarity'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nüìù Per-Edict Breakdown:\")\n",
    "for idx, row in df_edicts.iterrows():\n",
    "    edict_sents = df_sentences[df_sentences['edict_idx'] == idx]\n",
    "    num_form = edict_sents['is_formulaic'].sum()\n",
    "    total = len(edict_sents)\n",
    "    avg_sim = edict_sents[edict_sents['is_formulaic']]['max_similarity'].mean()\n",
    "    \n",
    "    print(f\"\\n   {row['text_title']}:\")\n",
    "    print(f\"     Total sentences: {total}\")\n",
    "    print(f\"     Formulaic: {num_form} ({num_form/total*100:.1f}%)\")\n",
    "    if num_form > 0:\n",
    "        print(f\"     Avg similarity: {avg_sim:.3f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files:\")\n",
    "print(f\"   1. {OUTPUT_FILE} - Formatted Markdown with bold highlighting\")\n",
    "print(f\"   2. {csv_file} - Detailed sentence-level CSV data\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "if num_formulaic > len(df_sentences) * 0.5:\n",
    "    print(f\"   High formulaic content ({num_formulaic/len(df_sentences)*100:.0f}%) suggests strong\")\n",
    "    print(f\"   adherence to template conventions in {EDICT_TYPE} edicts.\")\n",
    "elif num_formulaic > len(df_sentences) * 0.3:\n",
    "    print(f\"   Moderate formulaic content ({num_formulaic/len(df_sentences)*100:.0f}%) indicates a mix\")\n",
    "    print(f\"   of standard phrasing and edict-specific content.\")\n",
    "else:\n",
    "    print(f\"   Low formulaic content ({num_formulaic/len(df_sentences)*100:.0f}%) suggests high\")\n",
    "    print(f\"   variability and context-specific language in these edicts.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"‚úÖ Analysis complete!\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c854a",
   "metadata": {},
   "source": [
    "## 12. Visualize Edict Lengths and Formulaic Content\n",
    "\n",
    "Create a visual comparison of edict lengths showing the distribution of formulaic vs. unique content. Each edict is represented as a horizontal bar where colored segments indicate formulaic passages and white segments show unique content. This provides an at-a-glance view of how standardized language is distributed across different documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ac89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Configure matplotlib to display Chinese characters properly\n",
    "# Try to find available Chinese fonts on the system\n",
    "def get_chinese_font():\n",
    "    \"\"\"Find an available Chinese font on the system.\"\"\"\n",
    "    chinese_fonts = [\n",
    "        'WenQuanYi Micro Hei',  # Common on Linux\n",
    "        'WenQuanYi Zen Hei',\n",
    "        'Noto Sans CJK SC',\n",
    "        'Noto Sans CJK TC',\n",
    "        'Droid Sans Fallback',\n",
    "        'SimHei',  # Windows\n",
    "        'Arial Unicode MS',  # macOS\n",
    "        'Microsoft YaHei',\n",
    "        'STHeiti',\n",
    "    ]\n",
    "    \n",
    "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "    \n",
    "    for font in chinese_fonts:\n",
    "        if font in available_fonts:\n",
    "            print(f\"Using Chinese font: {font}\")\n",
    "            return font\n",
    "    \n",
    "    # If no Chinese font found, try the first CJK font available\n",
    "    for font_name in available_fonts:\n",
    "        if any(keyword in font_name.lower() for keyword in ['cjk', 'chinese', 'han', 'hei', 'song', 'kai']):\n",
    "            print(f\"Using Chinese font: {font_name}\")\n",
    "            return font_name\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  Warning: No Chinese font detected. Chinese characters may not display correctly.\")\n",
    "    print(\"   On Linux, install fonts with: sudo apt-get install fonts-wqy-microhei fonts-wqy-zenhei\")\n",
    "    return 'DejaVu Sans'\n",
    "\n",
    "chinese_font = get_chinese_font()\n",
    "plt.rcParams['font.sans-serif'] = [chinese_font, 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False  # Fix minus sign display\n",
    "\n",
    "print(\"Creating edict length visualization with formulaic content...\\n\")\n",
    "\n",
    "# Prepare data for visualization\n",
    "edict_viz_data = []\n",
    "\n",
    "for edict_idx, edict_row in df_edicts.iterrows():\n",
    "    # Get text without punctuation from text_contents column\n",
    "    text_no_punc = edict_row['text_contents'] if 'text_contents' in edict_row else edict_row['text_contents_punctuated']\n",
    "    # Remove common Chinese punctuation marks\n",
    "    for punct in ['„ÄÇ', 'Ôºõ', 'ÔºÅ', 'Ôºü', 'Ôºå', '„ÄÅ', 'Ôºö', '„Äå', '„Äç', '„Äé', '„Äè', 'Ôºà', 'Ôºâ', '„Ää', '„Äã']:\n",
    "        text_no_punc = text_no_punc.replace(punct, '')\n",
    "    \n",
    "    total_length = len(text_no_punc)\n",
    "    \n",
    "    # Get sentences for this edict\n",
    "    edict_sents = df_sentences[df_sentences['edict_idx'] == edict_idx].sort_values('start_pos')\n",
    "    \n",
    "    # Build segments for visualization\n",
    "    # Each segment is (start_char, end_char, is_formulaic)\n",
    "    segments = []\n",
    "    \n",
    "    for _, sent_row in edict_sents.iterrows():\n",
    "        # Calculate positions without punctuation\n",
    "        full_text_with_punc = edict_row['text_contents_punctuated']\n",
    "        start_pos_punc = sent_row['start_pos']\n",
    "        end_pos_punc = sent_row['end_pos']\n",
    "        \n",
    "        # Count characters without punctuation up to this point\n",
    "        text_before = full_text_with_punc[:start_pos_punc]\n",
    "        start_pos_no_punc = len(text_before)\n",
    "        for punct in ['„ÄÇ', 'Ôºõ', 'ÔºÅ', 'Ôºü', 'Ôºå', '„ÄÅ', 'Ôºö', '„Äå', '„Äç', '„Äé', '„Äè', 'Ôºà', 'Ôºâ', '„Ää', '„Äã']:\n",
    "            start_pos_no_punc -= text_before.count(punct)\n",
    "        \n",
    "        sent_text = full_text_with_punc[start_pos_punc:end_pos_punc]\n",
    "        sent_length_no_punc = len(sent_text)\n",
    "        for punct in ['„ÄÇ', 'Ôºõ', 'ÔºÅ', 'Ôºü', 'Ôºå', '„ÄÅ', 'Ôºö', '„Äå', '„Äç', '„Äé', '„Äè', 'Ôºà', 'Ôºâ', '„Ää', '„Äã']:\n",
    "            sent_length_no_punc -= sent_text.count(punct)\n",
    "        \n",
    "        end_pos_no_punc = start_pos_no_punc + sent_length_no_punc\n",
    "        \n",
    "        segments.append({\n",
    "            'start': start_pos_no_punc,\n",
    "            'end': end_pos_no_punc,\n",
    "            'is_formulaic': sent_row['is_formulaic']\n",
    "        })\n",
    "    \n",
    "    edict_viz_data.append({\n",
    "        'idx': edict_idx,\n",
    "        'title': edict_row['text_title'],\n",
    "        'length': total_length,\n",
    "        'segments': segments\n",
    "    })\n",
    "\n",
    "# Sort by length for better visualization\n",
    "edict_viz_data.sort(key=lambda x: x['length'], reverse=True)\n",
    "\n",
    "# Create the visualization\n",
    "fig, ax = plt.subplots(figsize=(14, max(6, len(edict_viz_data) * 0.6)))\n",
    "\n",
    "y_positions = range(len(edict_viz_data))\n",
    "bar_height = 0.7\n",
    "\n",
    "# Draw bars for each edict\n",
    "for i, edict_data in enumerate(edict_viz_data):\n",
    "    y_pos = len(edict_viz_data) - 1 - i  # Reverse order for top-to-bottom\n",
    "    \n",
    "    # Draw background (full length in light gray)\n",
    "    ax.barh(y_pos, edict_data['length'], height=bar_height, \n",
    "            color='#f0f0f0', edgecolor='gray', linewidth=0.5)\n",
    "    \n",
    "    # Draw formulaic segments in color\n",
    "    for segment in edict_data['segments']:\n",
    "        if segment['is_formulaic']:\n",
    "            seg_start = segment['start']\n",
    "            seg_width = segment['end'] - segment['start']\n",
    "            ax.barh(y_pos, seg_width, left=seg_start, height=bar_height,\n",
    "                   color='#ff6b6b', edgecolor='none')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_yticks(range(len(edict_viz_data)))\n",
    "ax.set_yticklabels([ed['title'] for ed in reversed(edict_viz_data)], fontsize=10, fontproperties=fm.FontProperties(family=chinese_font))\n",
    "ax.set_xlabel('Length (characters, excluding punctuation)', fontsize=12)\n",
    "ax.set_title(f'Edict Lengths and Formulaic Content Distribution - {EDICT_TYPE}', \n",
    "             fontsize=14, fontweight='bold', pad=20, fontproperties=fm.FontProperties(family=chinese_font))\n",
    "\n",
    "# Add grid for readability\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Add legend\n",
    "formulaic_patch = mpatches.Patch(color='#ff6b6b', label='Formulaic sentences')\n",
    "unique_patch = mpatches.Patch(color='#f0f0f0', label='Unique sentences')\n",
    "ax.legend(handles=[formulaic_patch, unique_patch], loc='lower right', fontsize=10, prop=fm.FontProperties(family=chinese_font))\n",
    "\n",
    "# Add text annotations showing exact lengths\n",
    "for i, edict_data in enumerate(edict_viz_data):\n",
    "    y_pos = len(edict_viz_data) - 1 - i\n",
    "    # Calculate formulaic character count\n",
    "    formulaic_chars = sum(seg['end'] - seg['start'] \n",
    "                          for seg in edict_data['segments'] \n",
    "                          if seg['is_formulaic'])\n",
    "    unique_chars = edict_data['length'] - formulaic_chars\n",
    "    formulaic_pct = (formulaic_chars / edict_data['length'] * 100) if edict_data['length'] > 0 else 0\n",
    "    \n",
    "    # Add text at the end of the bar\n",
    "    ax.text(edict_data['length'] + 50, y_pos, \n",
    "            f\"{edict_data['length']} chars ({formulaic_pct:.0f}% formulaic)\",\n",
    "            va='center', fontsize=9, color='#555')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"EDICT LENGTH SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n{'Edict Title':<50} {'Total':<10} {'Formulaic':<12} {'Unique':<10} {'% Formulaic':<12}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for edict_data in edict_viz_data:\n",
    "    formulaic_chars = sum(seg['end'] - seg['start'] \n",
    "                          for seg in edict_data['segments'] \n",
    "                          if seg['is_formulaic'])\n",
    "    unique_chars = edict_data['length'] - formulaic_chars\n",
    "    formulaic_pct = (formulaic_chars / edict_data['length'] * 100) if edict_data['length'] > 0 else 0\n",
    "    \n",
    "    title_short = edict_data['title'][:47] + '...' if len(edict_data['title']) > 50 else edict_data['title']\n",
    "    print(f\"{title_short:<50} {edict_data['length']:<10} {formulaic_chars:<12} {unique_chars:<10} {formulaic_pct:<12.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"Average edict length: {sum(ed['length'] for ed in edict_viz_data) / len(edict_viz_data):.0f} characters\")\n",
    "print(f\"Shortest edict: {min(ed['length'] for ed in edict_viz_data)} characters\")\n",
    "print(f\"Longest edict: {max(ed['length'] for ed in edict_viz_data)} characters\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea7519",
   "metadata": {},
   "source": [
    "## 13. Interactive Edict Explorer\n",
    "\n",
    "Compare edicts interactively with formulaic sentences highlighted:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ffbec",
   "metadata": {},
   "source": [
    "Parse the generated Markdown file to extract formatted edict texts. This reads back the formatted texts that were previously exported, organizing them into a data structure that can be used by the interactive widget. Each edict is stored with its title, formatted text (with ** bold markers), and associated sentence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the generated Markdown file to extract formatted texts\n",
    "print(f\"üìñ Reading formatted texts from {OUTPUT_FILE}...\")\n",
    "\n",
    "with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()\n",
    "\n",
    "# Parse the markdown to extract individual edicts with formatting\n",
    "# Split by edict headers (## Title format)\n",
    "edict_sections = re.split(r'\\n## ', markdown_content)\n",
    "\n",
    "# Skip the first section (header/metadata)\n",
    "edict_sections = edict_sections[1:] if len(edict_sections) > 1 else []\n",
    "\n",
    "# Store edict data with formatted text\n",
    "formatted_edicts = {}\n",
    "\n",
    "for section in edict_sections:\n",
    "    lines = section.strip().split('\\n')\n",
    "    if not lines:\n",
    "        continue\n",
    "    \n",
    "    # First line is the title\n",
    "    title = lines[0].strip()\n",
    "    \n",
    "    # Find the metadata line (starts with *)\n",
    "    text_start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith('*'):\n",
    "            text_start = i + 1\n",
    "            break\n",
    "    \n",
    "    if text_start is None or text_start >= len(lines):\n",
    "        continue\n",
    "    \n",
    "    # Collect text lines until we hit the separator (---)\n",
    "    text_lines = []\n",
    "    for i in range(text_start, len(lines)):\n",
    "        if lines[i].strip() == '---':\n",
    "            break\n",
    "        text_lines.append(lines[i])\n",
    "    \n",
    "    formatted_text = '\\n'.join(text_lines).strip()\n",
    "    \n",
    "    # Find the edict in our dataframe by matching title\n",
    "    matching_edicts = df_edicts[df_edicts['text_title'] == title]\n",
    "    if len(matching_edicts) > 0:\n",
    "        edict_idx = matching_edicts.index[0]\n",
    "        formatted_edicts[edict_idx] = {\n",
    "            'title': title,\n",
    "            'formatted_text': formatted_text,\n",
    "            'sentences': df_sentences[df_sentences['edict_idx'] == edict_idx]\n",
    "        }\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(formatted_edicts)} formatted edicts\")\n",
    "print(f\"   Formulaic sentences will be shown in **bold**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f5ea9",
   "metadata": {},
   "source": [
    "Define a function to find and compare similar edicts. This function identifies which other edicts share the most formulaic sentences with a selected edict. It calculates similarity scores based on the proportion of shared formulaic content and tracks exactly which sentences match between edicts. This data powers the interactive comparison feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89124cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_edicts_detailed(edict_idx, top_k=3):\n",
    "    \"\"\"\n",
    "    Find most similar edicts with detailed comparison.\n",
    "    Returns similarity scores, shared formulaic sentences, and matching sentence indices.\n",
    "    \"\"\"\n",
    "    edict_sentences = df_sentences[df_sentences['edict_idx'] == edict_idx]\n",
    "    formulaic_in_edict = edict_sentences[edict_sentences['is_formulaic']]\n",
    "    \n",
    "    # Find which other edicts share formulaic sentences\n",
    "    similarity_scores = {}\n",
    "    shared_formulas = {}\n",
    "    matching_sentence_indices = {}  # Track which sentences in other edicts match\n",
    "    \n",
    "    for other_idx in formatted_edicts.keys():\n",
    "        if other_idx == edict_idx:\n",
    "            continue\n",
    "        \n",
    "        # Count shared formulaic sentences between the two edicts\n",
    "        shared_count = 0\n",
    "        shared_texts = []\n",
    "        matching_indices = set()\n",
    "        \n",
    "        for _, sent in formulaic_in_edict.iterrows():\n",
    "            # Check if this sentence's best match is in the other edict\n",
    "            if pd.notna(sent['best_match_idx']):\n",
    "                match_idx = int(sent['best_match_idx'])\n",
    "                match_edict_idx = df_sentences.iloc[match_idx]['edict_idx']\n",
    "                if match_edict_idx == other_idx:\n",
    "                    shared_count += 1\n",
    "                    shared_texts.append(sent['sentence_text'])\n",
    "                    matching_indices.add(match_idx)\n",
    "        \n",
    "        if shared_count > 0:\n",
    "            # Calculate overall similarity as proportion of shared formulas\n",
    "            similarity = shared_count / max(len(formulaic_in_edict), 1)\n",
    "            similarity_scores[other_idx] = similarity\n",
    "            shared_formulas[other_idx] = shared_texts\n",
    "            matching_sentence_indices[other_idx] = matching_indices\n",
    "    \n",
    "    # Sort by similarity\n",
    "    sorted_edicts = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    return sorted_edicts, shared_formulas, matching_sentence_indices\n",
    "\n",
    "print(\"‚úÖ Similarity comparison function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c7839",
   "metadata": {},
   "source": [
    "Create an interactive widget for dynamic edict exploration. This widget allows you to:\n",
    "- Select any edict from a dropdown menu\n",
    "- View the full text with formulaic sentences highlighted in bold\n",
    "- See statistics about formulaic vs. unique content\n",
    "- Compare with the most similar edicts\n",
    "- Only matching sentences (not all formulaic ones) are highlighted in similar edicts\n",
    "\n",
    "The widget uses HTML rendering for proper bold formatting and provides an intuitive interface for exploring the formulaic patterns across the document collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3107a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget\n",
    "edict_options = [(data['title'], idx) for idx, data in formatted_edicts.items()]\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=edict_options,\n",
    "    description='Select Edict:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "show_comparison = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show similar edicts',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def format_text_with_bold(full_text, sentence_indices_to_bold):\n",
    "    \"\"\"\n",
    "    Format text with only specified sentences in bold.\n",
    "    \n",
    "    Args:\n",
    "        full_text: Original full text\n",
    "        sentence_indices_to_bold: Set of df_sentences indices to highlight\n",
    "        \n",
    "    Returns:\n",
    "        HTML formatted text\n",
    "    \"\"\"\n",
    "    if not sentence_indices_to_bold:\n",
    "        # No highlighting needed\n",
    "        return full_text.replace('\\n', '<br>')\n",
    "    \n",
    "    # Get all sentences for this text, sorted by position\n",
    "    sentences_to_format = df_sentences[df_sentences.index.isin(sentence_indices_to_bold)].sort_values('start_pos')\n",
    "    \n",
    "    # Build HTML with bold tags\n",
    "    result_html = \"\"\n",
    "    last_pos = 0\n",
    "    \n",
    "    for _, sent_row in sentences_to_format.iterrows():\n",
    "        start_pos = sent_row['start_pos']\n",
    "        end_pos = sent_row['end_pos']\n",
    "        \n",
    "        # Add text before this sentence\n",
    "        if start_pos > last_pos:\n",
    "            result_html += full_text[last_pos:start_pos]\n",
    "        \n",
    "        # Add this sentence in bold\n",
    "        result_html += '<strong>' + full_text[start_pos:end_pos] + '</strong>'\n",
    "        last_pos = end_pos\n",
    "    \n",
    "    # Add remaining text\n",
    "    if last_pos < len(full_text):\n",
    "        result_html += full_text[last_pos:]\n",
    "    \n",
    "    # Convert newlines to HTML breaks\n",
    "    result_html = result_html.replace('\\n', '<br>')\n",
    "    \n",
    "    return result_html\n",
    "\n",
    "def on_edict_select(change):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)  # Wait to clear until new output is ready\n",
    "        edict_idx = change['new']\n",
    "        edict_data = formatted_edicts[edict_idx]\n",
    "        \n",
    "        # Display selected edict with formatting\n",
    "        print(\"=\"*100)\n",
    "        print(f\"üìú Selected Edict: {edict_data['title']}\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Get statistics\n",
    "        edict_sents = edict_data['sentences']\n",
    "        num_formulaic = len(edict_sents[edict_sents['is_formulaic']])\n",
    "        num_total = len(edict_sents)\n",
    "        \n",
    "        print(f\"\\nüìä Statistics:\")\n",
    "        print(f\"   Total sentences: {num_total}\")\n",
    "        print(f\"   Formulaic sentences: {num_formulaic} ({num_formulaic/num_total*100:.1f}%)\")\n",
    "        print(f\"   Unique sentences: {num_total - num_formulaic} ({(num_total-num_formulaic)/num_total*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nüìñ Text (formulaic sentences in **bold**):\")\n",
    "        print(\"-\"*100)\n",
    "        \n",
    "        # Get the original full text and highlight formulaic sentences\n",
    "        full_text = df_edicts.loc[edict_idx, 'text_contents_punctuated']\n",
    "        formulaic_indices = set(edict_sents[edict_sents['is_formulaic']].index)\n",
    "        \n",
    "        html_output = format_text_with_bold(full_text, formulaic_indices)\n",
    "        display(HTML(f'<div style=\"white-space: pre-wrap; font-family: monospace; line-height: 1.8;\">{html_output}</div>'))\n",
    "        \n",
    "        # Show comparison with similar edicts\n",
    "        if show_comparison.value:\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"üîç Most Similar Edicts (by shared formulaic content)\")\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            similar, shared, matching_indices = find_similar_edicts_detailed(edict_idx, top_k=3)\n",
    "            \n",
    "            if not similar:\n",
    "                print(\"\\n   No similar edicts found with shared formulaic content.\")\n",
    "            else:\n",
    "                for i, (other_idx, score) in enumerate(similar, 1):\n",
    "                    other_data = formatted_edicts[other_idx]\n",
    "                    other_sents = other_data['sentences']\n",
    "                    other_formulaic = len(other_sents[other_sents['is_formulaic']])\n",
    "                    other_total = len(other_sents)\n",
    "                    \n",
    "                    print(f\"\\n{i}. {other_data['title']}\")\n",
    "                    print(f\"   Similarity: {score:.2%}\")\n",
    "                    print(f\"   Shared formulaic sentences: {len(shared[other_idx])}\")\n",
    "                    print(f\"   Total sentences: {other_total} (formulaic: {other_formulaic}/{other_total})\")\n",
    "                    print(f\"\\n   Full Text (matching phrases in **bold**):\")\n",
    "                    print(\"-\"*80)\n",
    "                    \n",
    "                    # Display the similar edict's full text with ONLY matching sentences in bold\n",
    "                    other_full_text = df_edicts.loc[other_idx, 'text_contents_punctuated']\n",
    "                    other_html_output = format_text_with_bold(other_full_text, matching_indices[other_idx])\n",
    "                    display(HTML(f'<div style=\"white-space: pre-wrap; font-family: monospace; line-height: 1.8; margin-left: 20px;\">{other_html_output}</div>'))\n",
    "                    \n",
    "                    print(\"\\n   Shared formulaic phrases (examples):\")\n",
    "                    for j, shared_text in enumerate(shared[other_idx][:5], 1):\n",
    "                        preview = shared_text[:100] + ('...' if len(shared_text) > 100 else '')\n",
    "                        print(f\"      ‚Ä¢ {preview}\")\n",
    "\n",
    "dropdown.observe(on_edict_select, names='value')\n",
    "\n",
    "print(\"üí° Interactive Edict Explorer\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nSelect an edict from the dropdown to:\")\n",
    "print(\"  ‚Ä¢ View the full text with formulaic sentences highlighted in bold\")\n",
    "print(\"  ‚Ä¢ See statistics about formulaic vs. unique content\")\n",
    "print(\"  ‚Ä¢ Compare with other similar edicts (full text shown)\")\n",
    "print(\"  ‚Ä¢ Only matching phrases are highlighted in similar edicts\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: First selection may take a moment to render the formatted text.\\n\")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([dropdown, show_comparison]),\n",
    "    output\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tang_edicts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
